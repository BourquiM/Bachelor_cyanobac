install.packages(c("cli", "lubridate", "RcppEigen", "stringi", "timechange"))
install.packages("lubridate")
R.Version()
print(R.Version())
v <- R.Version()
print(v)
install.packages("installr")
library(installr)
updateR()
install.packages(c("cli", "collections", "languageserver", "purrr", "roxygen2", "xfun"))
install.packages("xfun")
install.packages("purrr")
install.packages("xfun")
install.Rtools(check = TRUE, check_r_update = TRUE)
installr::install.Rtools()
install.Rtools()
setwd("~/GitHub/Bachelor_cyanobac/workplace2/Code")
source("A0_functions.R")  # The functions needed to run the code are stored in a separate file. This command imports the functions.
# Loading the necessary libraries
load_libraries()
# loading the data files
setwd("~/GitHub/Bachelor_cyanobac/workplace2/data_new")
databases()  # loading the databases metaDBphyto and metaDBzoo
phyto_raw <- read.csv("phyto.smallzoo.86-19_BAL.csv", sep = ",")  # loading the raw phytoplankton data
zoo_raw <- read.csv("largezoo.86-19_BAL.csv")  # loading the raw zooplankton data
setwd("~/GitHub/Bachelor_cyanobac/workplace2/data_new/temp_chem")  # loading the raw temperature and chemistry data
temp_chem <- read.csv("temp.chem.85-20_BAL.csv")
lake <- "BAL"  # Defining the name of the lake. This will be used when saving data in external files, to identify them later on
# Getting the phytoplankton data ready
ready_phyto_selec()  # setting the right data formats for the columns and adding the corresponding information from the meta database, for each entry
treat_noBiovolP(lake)  # Isolating the phyto data missing a biovolume value in the meta database
ready_phyto_clean()  # Removing entries without a metaDB-biovolume value and calculating the biovolume for the ones we keep
ready_phyto_agg()  # Aggregating phytoplankton biovolume per order and date
ready_phyto_final()  # Making the phytoplankton data ready for analysis and calculating difference and ratio between the phyto orders and the total phyto biovolume per day
# Getting the zooplankton data ready
ready_zoo_raw()  # Setting the right data formats
ready_zoo_agg()  # Aggregating the abundance of chosen orders/phyla/families per day
ready_zoo_final()  # Making the zooplankton data ready for analysis
# Getting the chemistry and temperature data ready
ready_temp_chem()  # Preparing the chemistry and temperature data
# It is best not to make the plots in functions, since the axes have to be set manually for each lake
{
# temp_chem %>% filter(NO3_N > 10)  # The line to show the outlier
temp_chem <- temp_chem %>% filter(NO3_N < 10)  # there is an outlier that's falsifying the whole data (and it isn't realistic) -> this step excludes it
# Creating the plots with the evolution of the temperature and chemistry of the lake over time
# Plotting the temperature alone
temp <- ggplot(data = temp_chem, aes(x = date, y = temperature)) +
geom_point(shape = 20, colour = "aquamarine4", size = 0.5) +
geom_smooth(colour = "aquamarine4") +
ggtitle(label = "Temperature over the years") +
labs(x = "Date", y = "Temperature [°C]")
# Plotting the Phosphate alone
po4 <- ggplot(data = temp_chem, aes(x = date, y = PO4_P)) +
geom_point(shape = 20, colour = "firebrick3", size = 0.5) +
geom_smooth(colour = "firebrick3") +
ggtitle(label = "PO4 over the years") +
labs(x = "Date", y = "PO4-P concentration [mg/L]")
# Plotting the Ammonia alone
nh4 <- ggplot(data = temp_chem, aes(x = date, y = NH4_N)) +
geom_point(shape = 20, colour = "cornflowerblue", size = 0.5) +
geom_smooth() +
ggtitle(label = "NH4 over the years") +
labs(x = "Date", y = "NH4-N concentration [mg/L]") +
scale_y_continuous(lim = c(0, 0.15))
# Plotting the Nitrate alone
no3 <- ggplot(data = temp_chem, aes(x = date, y = NO3_N)) +
geom_point(shape = 20, colour = "darkgoldenrod1", size = 0.5) +
geom_smooth(colour = "darkgoldenrod1") + # adding 'method = "gam"' shows the oscillation of the data points even more
ggtitle(label = "NO3 over the years") +
labs(x = "Date", y = "NO3-N concentration [mg/L]")
figure_tempchem <- ggarrange(temp, po4,
nh4, no3,
ncol = 2, nrow = 2)  # Putting the plots about chemistry and temperature together into a figure
figure_tempchem <- annotate_figure(figure_tempchem, top = text_grob(paste(lake, "lake"), face = "bold", size = 20))  # Adding a title to the figure
# Plotting the Nitrate and Ammonia in a single plot
coeff1 <- 20  # This variable is used to change the right y-axis size
no3_nh4 <- ggplot(data = temp_chem) +
geom_point(aes(x = date, y = NH4_N * coeff1, colour = "NH4"), size = 0.5) +
geom_point(aes(x = date, y = NO3_N, colour = "NO3"), size = 0.5) +
geom_smooth(aes(x = date, y = NH4_N * coeff1, colour = "NH4")) +
geom_smooth(aes(x = date, y = NO3_N, colour = "NO3")) +
scale_y_continuous(name = "NO3-N [mg/L]", lim = c(0, 3.5), sec.axis = sec_axis(trans=~./coeff1, name = "NH4-N [mg/L]")) +
ggtitle(label = "NO3 and NH4 over the years") +
scale_color_manual(name = "", breaks = c("NO3", "NH4"), values = c("NO3" = "darkgoldenrod1", "NH4" = "cornflowerblue")) +
theme(legend.position = "bottom")
# Plotting the Phosphate and temperature in a single plot
coeff2 <- 60
temp_po4 <- ggplot(data = temp_chem) +
geom_point(aes(x = date, y = temperature, colour = "Temperature"), size = 0.5) +
geom_point(aes(x = date, y = PO4_P * coeff2, colour = "PO4"), size = 0.5) +
geom_smooth(aes(x = date, y = temperature, colour = "Temperature")) +
geom_smooth(aes(x = date, y = PO4_P * coeff2, colour = "PO4")) +
scale_y_continuous(name = "Temperature [°C]", sec.axis = sec_axis(trans=~./coeff2, name = "PO4-P [mg/L]")) +
ggtitle(label = "Temperature and PO4 over the years") +
scale_color_manual(name = "", breaks = c("Temperature", "PO4"), values = c("Temperature" = "aquamarine4", "PO4" = "firebrick3")) +
theme(legend.position = "bottom", plot.title = element_text(size = 10))
} #
# Putting the phytoplankton, zooplankton and chemistry + temperature data into a single frame
ready_end_frame()  # Gathering all the phytoplankton, zooplankton, temperature and chemistry data into a single data frame. And making it ready for analysis
summary(end_frame)
rf_frame <- end_frame %>% select(-c(date, depth))
str(end_frame)
str(rf_frame)
View(rf_frame)
setwd("~/GitHub/Bachelor_cyanobac/workplace2/Code")
source("A0_functions.R")  # The functions needed to run the code are stored in a separate file. This command imports the functions.
# Loading the necessary libraries
load_libraries()
# loading the data files
setwd("~/GitHub/Bachelor_cyanobac/workplace2/data_new")
databases()  # loading the databases metaDBphyto and metaDBzoo
phyto_raw <- read.csv("phyto.smallzoo.86-19_BAL.csv", sep = ",")  # loading the raw phytoplankton data
zoo_raw <- read.csv("largezoo.86-19_BAL.csv")  # loading the raw zooplankton data
setwd("~/GitHub/Bachelor_cyanobac/workplace2/data_new/temp_chem")  # loading the raw temperature and chemistry data
temp_chem <- read.csv("temp.chem.85-20_BAL.csv")
lake <- "BAL"  # Defining the name of the lake. This will be used when saving data in external files, to identify them later on
# Getting the phytoplankton data ready
ready_phyto_selec()  # setting the right data formats for the columns and adding the corresponding information from the meta database, for each entry
treat_noBiovolP(lake)  # Isolating the phyto data missing a biovolume value in the meta database
ready_phyto_clean()  # Removing entries without a metaDB-biovolume value and calculating the biovolume for the ones we keep
ready_phyto_agg()  # Aggregating phytoplankton biovolume per order and date
ready_phyto_final()  # Making the phytoplankton data ready for analysis and calculating difference and ratio between the phyto orders and the total phyto biovolume per day
# Getting the zooplankton data ready
ready_zoo_raw()  # Setting the right data formats
ready_zoo_agg()  # Aggregating the abundance of chosen orders/phyla/families per day
ready_zoo_final()  # Making the zooplankton data ready for analysis
# Getting the chemistry and temperature data ready
ready_temp_chem()  # Preparing the chemistry and temperature data
# It is best not to make the plots in functions, since the axes have to be set manually for each lake
{
# temp_chem %>% filter(NO3_N > 10)  # The line to show the outlier
temp_chem <- temp_chem %>% filter(NO3_N < 10)  # there is an outlier that's falsifying the whole data (and it isn't realistic) -> this step excludes it
# Creating the plots with the evolution of the temperature and chemistry of the lake over time
# Plotting the temperature alone
temp <- ggplot(data = temp_chem, aes(x = date, y = temperature)) +
geom_point(shape = 20, colour = "aquamarine4", size = 0.5) +
geom_smooth(colour = "aquamarine4") +
ggtitle(label = "Temperature over the years") +
labs(x = "Date", y = "Temperature [°C]")
# Plotting the Phosphate alone
po4 <- ggplot(data = temp_chem, aes(x = date, y = PO4_P)) +
geom_point(shape = 20, colour = "firebrick3", size = 0.5) +
geom_smooth(colour = "firebrick3") +
ggtitle(label = "PO4 over the years") +
labs(x = "Date", y = "PO4-P concentration [mg/L]")
# Plotting the Ammonia alone
nh4 <- ggplot(data = temp_chem, aes(x = date, y = NH4_N)) +
geom_point(shape = 20, colour = "cornflowerblue", size = 0.5) +
geom_smooth() +
ggtitle(label = "NH4 over the years") +
labs(x = "Date", y = "NH4-N concentration [mg/L]") +
scale_y_continuous(lim = c(0, 0.15))
# Plotting the Nitrate alone
no3 <- ggplot(data = temp_chem, aes(x = date, y = NO3_N)) +
geom_point(shape = 20, colour = "darkgoldenrod1", size = 0.5) +
geom_smooth(colour = "darkgoldenrod1") + # adding 'method = "gam"' shows the oscillation of the data points even more
ggtitle(label = "NO3 over the years") +
labs(x = "Date", y = "NO3-N concentration [mg/L]")
figure_tempchem <- ggarrange(temp, po4,
nh4, no3,
ncol = 2, nrow = 2)  # Putting the plots about chemistry and temperature together into a figure
figure_tempchem <- annotate_figure(figure_tempchem, top = text_grob(paste(lake, "lake"), face = "bold", size = 20))  # Adding a title to the figure
# Plotting the Nitrate and Ammonia in a single plot
coeff1 <- 20  # This variable is used to change the right y-axis size
no3_nh4 <- ggplot(data = temp_chem) +
geom_point(aes(x = date, y = NH4_N * coeff1, colour = "NH4"), size = 0.5) +
geom_point(aes(x = date, y = NO3_N, colour = "NO3"), size = 0.5) +
geom_smooth(aes(x = date, y = NH4_N * coeff1, colour = "NH4")) +
geom_smooth(aes(x = date, y = NO3_N, colour = "NO3")) +
scale_y_continuous(name = "NO3-N [mg/L]", lim = c(0, 3.5), sec.axis = sec_axis(trans=~./coeff1, name = "NH4-N [mg/L]")) +
ggtitle(label = "NO3 and NH4 over the years") +
scale_color_manual(name = "", breaks = c("NO3", "NH4"), values = c("NO3" = "darkgoldenrod1", "NH4" = "cornflowerblue")) +
theme(legend.position = "bottom")
# Plotting the Phosphate and temperature in a single plot
coeff2 <- 60
temp_po4 <- ggplot(data = temp_chem) +
geom_point(aes(x = date, y = temperature, colour = "Temperature"), size = 0.5) +
geom_point(aes(x = date, y = PO4_P * coeff2, colour = "PO4"), size = 0.5) +
geom_smooth(aes(x = date, y = temperature, colour = "Temperature")) +
geom_smooth(aes(x = date, y = PO4_P * coeff2, colour = "PO4")) +
scale_y_continuous(name = "Temperature [°C]", sec.axis = sec_axis(trans=~./coeff2, name = "PO4-P [mg/L]")) +
ggtitle(label = "Temperature and PO4 over the years") +
scale_color_manual(name = "", breaks = c("Temperature", "PO4"), values = c("Temperature" = "aquamarine4", "PO4" = "firebrick3")) +
theme(legend.position = "bottom", plot.title = element_text(size = 10))
} #
# Putting the phytoplankton, zooplankton and chemistry + temperature data into a single frame
ready_end_frame()  # Gathering all the phytoplankton, zooplankton, temperature and chemistry data into a single data frame. And making it ready for analysis
library(caret)
View(end_frame)
str(end_frame)
# selecting only the data we want to include in the analysis
summary(end_frame)
?featurePlot()
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N")], y = end_frame$r_cyanobac, plot = "pairs")
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N")], y = end_frame$r_cyanobac, plot = "scatter")
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame$r_cyanobac, plot = "scatter")
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame$r_cyanobac, plot = "scatter", main = "title")
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame$r_cyanobac, plot = "scatter", labels ="gagu")
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame$r_cyanobac, plot = "scatter", labels = c("", "r_cyanobac"))
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame$r_cyanobac, plot = "scatter", labels = c("", "ratio cyanobac - tot_phyto"))
?nearZeroVar()
nearZeroVar(x = end_frame)
names(end_frame[,nearZeroVar(x = end_frame)])
names(end_frame[nearZeroVar(x = end_frame)],)
names(end_frame[nearZeroVar(x = end_frame),])
nearZeroVar(x = end_frame)
end_frame %>% select(19)
nearZeorVar(x = end_frame, freqCut = 80/20)
nearZeroVar(x = end_frame, freqCut = 80/20)
nearZeroVar(x = end_frame, freqCut = 80/20, uniqueCut = 20)
nearZeroVar(x = end_frame, freqCut = 70/30, uniqueCut = 20) # And even after
nearZeroVar(x = end_frame, freqCut = 70/30, uniqueCut = 50) # And even after
trainIndex <- createDataPartition(end_frame, p = 0.7, list = FALSE)
?createDataPartition
trainIndex <- createDataPartition(end_frame, p = 0.7, list = TRUE)
trainIndex <- createDataPartition(end_frame$r_cyanobac, p = 0.7, list = TRUE)
View(trainIndex)
trainSet <- end_frame[trainIndex, ]
trainIndex <- createDataPartition(end_frame$r_cyanobac, p = 0.7, list = FALSE)
trainSet <- end_frame[trainIndex, ]
testSet <- end_frame[-trainIndex, ]
summary(trainSet)
end_frame <- end_frame %>% select(-c(date, depth))
# Would make sense to create a function creating the 3D graphs he showed me
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame$r_cyanobac, plot = "scatter", labels = c("", "ratio cyanobac - tot_phyto"))
set.seed(123) # doesn't need to be 355, but having a value here makes the test reproducible
trainIndex <- createDataPartition(end_frame$r_cyanobac, p = 0.7, list = FALSE)
trainSet <- end_frame[trainIndex, ]
testSet <- end_frame[-trainIndex, ]
summary(trainSet)
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainSet, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
View(end_frame)
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame[, c("chrooco", "nosto", "oscillato")], plot = "scatter", labels = c("", "ratio cyanobac - tot_phyto"))
featurePlot(x = end_frame[, c("tot_phyto", "NH4_N", "NO3_N", "temperature")], y = end_frame[, c("chrooco", "nosto", "oscillato")], plot = "scatter", labels = c("", "ratio cyanobac - tot_phyto"))
?preProcess()
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale"))  # Creating the model that will transform the data
training <- end_frame[trainIndex, ]  # creating the training data set
test <- end_frame[-trainIndex, ]  # creating the testing data set
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = training, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
training <- end_frame[trainIndex, ]  # creating the training data set
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale"), k = 20)  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
testTransformed <- predict(preProcValues, newdata = test)  # transformation of the testing data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
gaga <- preProcess(x = training, method = "bagImpute")
trainy <- predict(gaga, newdata = training)
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = gaga, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
?bagImpute
??bagImpute
View(end_frame)
system.time(rf_r_cyanobac1 <- train(r_cyanobac ~ NH4_N:calanoida, data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac1
r_cyanobac_frame <- end_frame %>% select(r_cyanobac, NH4_N:calanoida)
View(r_cyanobac_frame)
r_cyanobac_frame <- end_frame %>% select(r_cyanobac, NH4_N:calanoida)
# Partitioning the data
set.seed(123) # doesn't need to be 355, but having a value here makes the test reproducible
trainIndex <- createDataPartition(r_cyanobac_frame$r_cyanobac, p = 0.7, list = FALSE)  # Choosing which indices of the data set will be for training, and which ones for testing. 70% are for training, 30% for testing
training <- r_cyanobac_frame[trainIndex, ]  # creating the training data set
test <- r_cyanobac_frame[-trainIndex, ]  # creating the testing data set
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale"), k = 20)  # Creating the model that will transform the data
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
gaga <- preProcess(x = training, method = "bagImpute")
trainy <- predict(gaga, newdata = training)
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale", "bagimpute"))  # Creating the model that will transform the data
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale", "bagImpute"))  # Creating the model that will transform the data
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10), num.trees = 999, importance = "permutation"))
system.time(rf_r_cyanobac1 <- train(r_cyanobac ~ NH4_N:calanoida, data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10), num.trees = 999, importance = "permutation"))
system.time(rf_r_cyanobac1 <- train(r_cyanobac ~ NH4_N + NO3_N + PO4_P + temperature, data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
system.time(rf_r_cyanobac1 <- train(r_cyanobac ~ NH4_N + NO3_N + PO4_P + temperature, data = trainy, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10), num.trees = 999, importance = "permutation"))
rf_r_cyanobac1
r_cyanobac_frame <- end_frame %>% select(r_cyanobac, NH4_N:calanoida)
# Partitioning the data
set.seed(123) # doesn't need to be 355, but having a value here makes the test reproducible
trainIndex <- createDataPartition(r_cyanobac_frame$r_cyanobac, p = 0.7, list = FALSE)  # Choosing which indices of the data set will be for training, and which ones for testing. 70% are for training, 30% for testing
training <- r_cyanobac_frame[trainIndex, ]  # creating the training data set
test <- r_cyanobac_frame[-trainIndex, ]  # creating the testing data set
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale", "bagImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = preProcValues, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = training, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
preProcValues <- preProcess(x = training, method = c("medianImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale", "bagImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
system.time(rf_r_cyanobac1 <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale", "bagImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
preProcValues <- preProcess(x = training, method = c("medianImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
system.time(rf_r_cyanobac1 <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
rf_r_cyanobac1
# Pre-processing the data
preProcValues <- preProcess(x = training, method = c("center", "scale", "bagImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
preProcValues <- preProcess(x = training, method = c("center", "scale" ,"medianImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
preProcValues <- preProcess(x = training, method = c("bagImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
preProcValues <- preProcess(x = training, method = c("medianImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
preProcValues <- preProcess(x = training, method = c("bagImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
preProcValues <- preProcess(x = training, method = c("medianImpute"))  # Creating the model that will transform the data
trainTransformed <- predict(preProcValues, newdata = training)  # transformation of the training data set into Z-scores, using the model we just created
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = trainTransformed, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = training, method = "rf", importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
View(training)
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = training, method = "rf", na.action = na.ignore, importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
??na.action
?na.action
# This one has 10 fold cross-validation and importance ranking of the variables
system.time(rf_r_cyanobac <- train(r_cyanobac ~., data = training, method = "rf", na.action = na.omit, importance = TRUE, trControl = trainControl(method = "cv", number = 10)))
rf_r_cyanobac
# Realizing the imputation
pre_knn <- preProcess(r_cyanobac_frame, method = "knnImpute", k = 10)
pre_bag <- preProcess(r_cyanobac_frame, method = "bagImpute")
pre_median <- preProcess(r_cyanobac_frame, method = "medianImpute")
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = r_cyanobac_frame)
imputed_bag <- predict(pre_bag, newdata = r_cyanobac_frame)
imputed_median <- predict(pre_median, newdata = r_cyanobac_frame)
install.packages(c("cli", "collections", "languageserver", "purrr", "recipes", "roxygen2", "stringi", "timechange", "xfun"))
install.packages("RANN")
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = r_cyanobac_frame)
View(imputed_bag)
View_traingin
# Realizing the imputation
pre_knn <- preProcess(training, method = "knnImpute", k = 10)
pre_bag <- preProcess(training, method = "bagImpute")
pre_median <- preProcess(training, method = "medianImpute")
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = r_cyanobac_frame)
imputed_bag <- predict(pre_bag, newdata = r_cyanobac_frame)
imputed_median <- predict(pre_median, newdata = r_cyanobac_frame)
e
e
e
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = training)
imputed_bag <- predict(pre_bag, newdata = training)
imputed_median <- predict(pre_median, newdata = training)
View(imputed_knn)
View(imputed_median)
# Realizing the imputation
pre_knn <- preProcess(training, method = "knnImpute", k = 10)
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = training)
# Realizing the imputation
pre_knn <- preProcess(training, method = "knnImpute", k = 2)
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = training)
=knnImpute
?knnImpute
??knnImpute
# Realizing the imputation
pre_knn <- preProcess(training, method = "knnImpute", k = round(sqrt(nrow(training))))
# Applying it to the data
imputed_knn <- predict(pre_knn, newdata = training)
mean(training %>% select(temperature))
mean(training$temperature)
# Realizing the imputation
pre_knn <- preProcess(training, method = "knnImpute", k = round(sqrt(nrow(training))), verbose = T)
mean(training %>% select(temperature))
mean(training$temperature)
sd(training$temperature)
(3.226667 - 7.565091)/2.251201
